{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab81620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset shape: (666192, 2)\n",
      "\n",
      "üè∑Ô∏è Class distribution:\n",
      "type\n",
      "benign        435103\n",
      "phishing       99111\n",
      "defacement     97457\n",
      "malware        34520\n",
      "type               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "type\n",
      "benign        65.311952\n",
      "phishing      14.877243\n",
      "defacement    14.628966\n",
      "malware        5.181689\n",
      "type           0.000150\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "üîç Duplicate URLs: 16283\n",
      "‚úÖ After removing duplicates: 649909 rows\n",
      "\n",
      "üìä Sample URLs:\n",
      "                                                 url        type\n",
      "0                                   br-icloud.com.br    phishing\n",
      "1                mp3raid.com/music/krizz_kaliko.html      benign\n",
      "2                    bopsecrets.org/rexroth/cr/1.htm      benign\n",
      "3  http://www.garage-pirenne.be/index.php?option=...  defacement\n",
      "4  http://adventure-nicaragua.net/index.php?optio...  defacement\n",
      "5  http://buzzfil.net/m/show-art/ils-etaient-loin...      benign\n",
      "6      espn.go.com/nba/player/_/id/3457/brandon-rush      benign\n",
      "7     yourbittorrent.com/?q=anthony-hamilton-soulife      benign\n",
      "8       http://www.pashminaonline.com/pure-pashminas  defacement\n",
      "9      allmusic.com/album/crazy-from-the-heat-r16990      benign\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import joblib\n",
    "import time\n",
    "import string\n",
    "\n",
    "df = pd.read_csv(\"malicious_phish.csv\")\n",
    "\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"\\nüè∑Ô∏è Class distribution:\")\n",
    "print(df['type'].value_counts())\n",
    "print(f\"\\n{df['type'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Remove duplicates\n",
    "print(f\"\\nüîç Duplicate URLs: {df['url'].duplicated().sum()}\")\n",
    "df = df.drop_duplicates(subset=['url'])\n",
    "print(f\"‚úÖ After removing duplicates: {len(df)} rows\")\n",
    "\n",
    "print(f\"\\nüìä Sample URLs:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1792370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Extracting enhanced features...\n",
      "‚úÖ Feature matrix shape: (649909, 33)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üìå ENHANCED FEATURE ENGINEERING\n",
    "# ===============================\n",
    "\n",
    "def extract_advanced_features(url):\n",
    "    \"\"\"Extract comprehensive features from URL with additional complexity\"\"\"\n",
    "    url = str(url)\n",
    "    \n",
    "    # Parse URL components\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        domain = parsed.netloc\n",
    "        path = parsed.path\n",
    "    except:\n",
    "        domain = \"\"\n",
    "        path = \"\"\n",
    "    \n",
    "    features = {\n",
    "        # Length features\n",
    "        \"url_length\": len(url),\n",
    "        \"domain_length\": len(domain),\n",
    "        \"path_length\": len(path),\n",
    "        \n",
    "        # Character composition\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_letters\": sum(c.isalpha() for c in url),\n",
    "        \"num_specials\": sum(c in ['@','-','?','=','%','/','&','#','.'] for c in url),\n",
    "        \"digit_ratio\": sum(c.isdigit() for c in url) / len(url) if len(url) > 0 else 0,\n",
    "        \"letter_ratio\": sum(c.isalpha() for c in url) / len(url) if len(url) > 0 else 0,\n",
    "        \n",
    "        # Protocol & security\n",
    "        \"has_https\": int(\"https\" in url.lower()),\n",
    "        \"has_http\": int(\"http://\" in url.lower()),\n",
    "        \n",
    "        # Suspicious keywords\n",
    "        \"has_login\": int(any(word in url.lower() for word in [\"login\", \"signin\", \"account\"])),\n",
    "        \"has_secure\": int(\"secure\" in url.lower()),\n",
    "        \"has_update\": int(\"update\" in url.lower()),\n",
    "        \"has_banking\": int(any(word in url.lower() for word in [\"bank\", \"paypal\", \"payment\"])),\n",
    "        \"has_verify\": int(\"verify\" in url.lower() or \"confirm\" in url.lower()),\n",
    "        \n",
    "        # Structure features\n",
    "        \"num_dots\": url.count('.'),\n",
    "        \"num_hyphens\": url.count('-'),\n",
    "        \"num_underscores\": url.count('_'),\n",
    "        \"num_slashes\": url.count('/'),\n",
    "        \"num_questions\": url.count('?'),\n",
    "        \"num_equals\": url.count('='),\n",
    "        \"num_ats\": url.count('@'),\n",
    "        \"num_ampersands\": url.count('&'),\n",
    "        \n",
    "        # Domain features\n",
    "        \"num_subdomains\": domain.count('.'),\n",
    "        \"has_ip\": int(bool(re.search(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', url))),\n",
    "        \n",
    "        # Entropy (randomness measure)\n",
    "        \"entropy\": -sum((url.count(c)/len(url))*np.log2(url.count(c)/len(url)) \n",
    "                       for c in set(url)) if len(url) > 0 else 0,\n",
    "        \n",
    "        # Suspicious patterns\n",
    "        \"has_double_slash\": int('//' in url[8:]),\n",
    "        \"has_port\": int(':' in domain),\n",
    "        \"abnormal_tld\": int(url.endswith(('.tk', '.ml', '.ga', '.cf', '.gq'))),\n",
    "        \n",
    "        # NEW: Additional complexity features\n",
    "        \"uppercase_count\": sum(c.isupper() for c in url),\n",
    "        \"consecutive_digits\": max([len(x) for x in re.findall(r'\\d+', url)] or [0]),\n",
    "        \"consecutive_letters\": max([len(x) for x in re.findall(r'[a-zA-Z]+', url)] or [0]),\n",
    "        \"special_char_ratio\": sum(c in string.punctuation for c in url) / len(url) if len(url) > 0 else 0,\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\nüìä Extracting enhanced features...\")\n",
    "feature_df = pd.DataFrame([extract_advanced_features(u) for u in df[\"url\"]])\n",
    "print(f\"‚úÖ Feature matrix shape: {feature_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488c7f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Creating advanced TF-IDF representation...\n",
      "‚úÖ TF-IDF matrix shape: (649909, 3000)\n",
      "‚úÖ Combined feature matrix shape: (649909, 3033)\n",
      "\n",
      "üè∑Ô∏è Classes mapping: {'benign': np.int64(0), 'defacement': np.int64(1), 'malware': np.int64(2), 'phishing': np.int64(3), 'type': np.int64(4)}\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üìå ADVANCED TF-IDF VECTORIZATION\n",
    "# ===============================\n",
    "\n",
    "print(\"\\nüìù Creating advanced TF-IDF representation...\")\n",
    "\n",
    "# Character-level n-grams\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='char_wb',\n",
    "    ngram_range=(2,5),\n",
    "    max_features=3000,\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(df[\"url\"])\n",
    "print(f\"‚úÖ TF-IDF matrix shape: {X_tfidf.shape}\")\n",
    "\n",
    "# Combine features\n",
    "X_numeric = csr_matrix(feature_df.values)\n",
    "X_all = hstack([X_tfidf, X_numeric], format='csr')\n",
    "print(f\"‚úÖ Combined feature matrix shape: {X_all.shape}\")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"type\"])\n",
    "print(f\"\\nüè∑Ô∏è Classes mapping: {dict(zip(le.classes_, le.transform(le.classes_)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfbc9039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Performing full XGBoost cross-validation (5-fold)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.40741+0.00007\ttrain-merror:0.06167+0.00040\ttest-mlogloss:1.40754+0.00019\ttest-merror:0.06224+0.00084\n",
      "[25]\ttrain-mlogloss:0.24516+0.00032\ttrain-merror:0.04563+0.00014\ttest-mlogloss:0.24680+0.00141\ttest-merror:0.04621+0.00074\n",
      "[50]\ttrain-mlogloss:0.12880+0.00056\ttrain-merror:0.03551+0.00029\ttest-mlogloss:0.13183+0.00123\ttest-merror:0.03638+0.00027\n",
      "[75]\ttrain-mlogloss:0.10156+0.00049\ttrain-merror:0.03004+0.00014\ttest-mlogloss:0.10569+0.00133\ttest-merror:0.03136+0.00050\n",
      "[100]\ttrain-mlogloss:0.08836+0.00040\ttrain-merror:0.02654+0.00017\ttest-mlogloss:0.09362+0.00127\ttest-merror:0.02824+0.00048\n",
      "[125]\ttrain-mlogloss:0.08008+0.00035\ttrain-merror:0.02411+0.00020\ttest-mlogloss:0.08625+0.00119\ttest-merror:0.02607+0.00051\n",
      "[150]\ttrain-mlogloss:0.07407+0.00036\ttrain-merror:0.02232+0.00021\ttest-mlogloss:0.08123+0.00111\ttest-merror:0.02468+0.00043\n",
      "[175]\ttrain-mlogloss:0.06935+0.00035\ttrain-merror:0.02090+0.00023\ttest-mlogloss:0.07745+0.00107\ttest-merror:0.02351+0.00049\n",
      "[200]\ttrain-mlogloss:0.06536+0.00034\ttrain-merror:0.01974+0.00019\ttest-mlogloss:0.07435+0.00107\ttest-merror:0.02270+0.00045\n",
      "[225]\ttrain-mlogloss:0.06193+0.00036\ttrain-merror:0.01870+0.00021\ttest-mlogloss:0.07175+0.00101\ttest-merror:0.02195+0.00045\n",
      "[250]\ttrain-mlogloss:0.05889+0.00037\ttrain-merror:0.01785+0.00019\ttest-mlogloss:0.06952+0.00087\ttest-merror:0.02139+0.00036\n",
      "[275]\ttrain-mlogloss:0.05625+0.00036\ttrain-merror:0.01709+0.00019\ttest-mlogloss:0.06763+0.00088\ttest-merror:0.02090+0.00031\n",
      "[300]\ttrain-mlogloss:0.05391+0.00032\ttrain-merror:0.01639+0.00014\ttest-mlogloss:0.06602+0.00085\ttest-merror:0.02049+0.00031\n",
      "[325]\ttrain-mlogloss:0.05176+0.00032\ttrain-merror:0.01579+0.00017\ttest-mlogloss:0.06457+0.00085\ttest-merror:0.02007+0.00028\n",
      "[350]\ttrain-mlogloss:0.04977+0.00027\ttrain-merror:0.01519+0.00013\ttest-mlogloss:0.06325+0.00091\ttest-merror:0.01968+0.00028\n",
      "[375]\ttrain-mlogloss:0.04804+0.00022\ttrain-merror:0.01468+0.00013\ttest-mlogloss:0.06219+0.00091\ttest-merror:0.01940+0.00029\n",
      "[400]\ttrain-mlogloss:0.04639+0.00025\ttrain-merror:0.01419+0.00013\ttest-mlogloss:0.06114+0.00091\ttest-merror:0.01915+0.00029\n",
      "[425]\ttrain-mlogloss:0.04487+0.00019\ttrain-merror:0.01376+0.00011\ttest-mlogloss:0.06022+0.00094\ttest-merror:0.01885+0.00035\n",
      "[450]\ttrain-mlogloss:0.04347+0.00019\ttrain-merror:0.01337+0.00011\ttest-mlogloss:0.05943+0.00092\ttest-merror:0.01863+0.00031\n",
      "[475]\ttrain-mlogloss:0.04217+0.00020\ttrain-merror:0.01300+0.00012\ttest-mlogloss:0.05868+0.00093\ttest-merror:0.01841+0.00032\n",
      "[500]\ttrain-mlogloss:0.04092+0.00018\ttrain-merror:0.01262+0.00015\ttest-mlogloss:0.05797+0.00093\ttest-merror:0.01821+0.00036\n",
      "[525]\ttrain-mlogloss:0.03979+0.00018\ttrain-merror:0.01226+0.00013\ttest-mlogloss:0.05737+0.00093\ttest-merror:0.01806+0.00033\n",
      "[550]\ttrain-mlogloss:0.03868+0.00015\ttrain-merror:0.01190+0.00013\ttest-mlogloss:0.05677+0.00093\ttest-merror:0.01788+0.00032\n",
      "[575]\ttrain-mlogloss:0.03760+0.00016\ttrain-merror:0.01156+0.00013\ttest-mlogloss:0.05619+0.00093\ttest-merror:0.01773+0.00034\n",
      "[600]\ttrain-mlogloss:0.03659+0.00017\ttrain-merror:0.01123+0.00015\ttest-mlogloss:0.05566+0.00090\ttest-merror:0.01762+0.00037\n",
      "[625]\ttrain-mlogloss:0.03567+0.00017\ttrain-merror:0.01093+0.00013\ttest-mlogloss:0.05520+0.00092\ttest-merror:0.01748+0.00036\n",
      "[650]\ttrain-mlogloss:0.03475+0.00016\ttrain-merror:0.01064+0.00013\ttest-mlogloss:0.05474+0.00092\ttest-merror:0.01739+0.00034\n",
      "[675]\ttrain-mlogloss:0.03392+0.00015\ttrain-merror:0.01036+0.00012\ttest-mlogloss:0.05434+0.00092\ttest-merror:0.01731+0.00035\n",
      "[700]\ttrain-mlogloss:0.03311+0.00017\ttrain-merror:0.01009+0.00010\ttest-mlogloss:0.05395+0.00091\ttest-merror:0.01720+0.00034\n",
      "[725]\ttrain-mlogloss:0.03236+0.00017\ttrain-merror:0.00984+0.00011\ttest-mlogloss:0.05361+0.00090\ttest-merror:0.01711+0.00033\n",
      "[750]\ttrain-mlogloss:0.03161+0.00017\ttrain-merror:0.00958+0.00010\ttest-mlogloss:0.05327+0.00089\ttest-merror:0.01700+0.00032\n",
      "[775]\ttrain-mlogloss:0.03088+0.00014\ttrain-merror:0.00934+0.00008\ttest-mlogloss:0.05294+0.00092\ttest-merror:0.01689+0.00035\n",
      "[800]\ttrain-mlogloss:0.03020+0.00014\ttrain-merror:0.00910+0.00009\ttest-mlogloss:0.05263+0.00092\ttest-merror:0.01682+0.00033\n",
      "[825]\ttrain-mlogloss:0.02952+0.00017\ttrain-merror:0.00886+0.00009\ttest-mlogloss:0.05235+0.00091\ttest-merror:0.01677+0.00033\n",
      "[850]\ttrain-mlogloss:0.02885+0.00017\ttrain-merror:0.00861+0.00010\ttest-mlogloss:0.05205+0.00092\ttest-merror:0.01665+0.00036\n",
      "[875]\ttrain-mlogloss:0.02823+0.00016\ttrain-merror:0.00838+0.00008\ttest-mlogloss:0.05178+0.00094\ttest-merror:0.01657+0.00041\n",
      "[900]\ttrain-mlogloss:0.02765+0.00016\ttrain-merror:0.00815+0.00010\ttest-mlogloss:0.05156+0.00094\ttest-merror:0.01651+0.00036\n",
      "[925]\ttrain-mlogloss:0.02709+0.00016\ttrain-merror:0.00793+0.00007\ttest-mlogloss:0.05135+0.00094\ttest-merror:0.01649+0.00037\n",
      "[950]\ttrain-mlogloss:0.02653+0.00015\ttrain-merror:0.00772+0.00008\ttest-mlogloss:0.05113+0.00096\ttest-merror:0.01644+0.00037\n",
      "[975]\ttrain-mlogloss:0.02599+0.00016\ttrain-merror:0.00752+0.00010\ttest-mlogloss:0.05091+0.00093\ttest-merror:0.01635+0.00036\n",
      "[999]\ttrain-mlogloss:0.02548+0.00014\ttrain-merror:0.00735+0.00009\ttest-mlogloss:0.05072+0.00095\ttest-merror:0.01630+0.00033\n",
      "\n",
      "‚úÖ Best CV round: 1000\n",
      "     train-mlogloss-mean  train-mlogloss-std  train-merror-mean  \\\n",
      "995             0.025566            0.000140           0.007376   \n",
      "996             0.025545            0.000141           0.007368   \n",
      "997             0.025526            0.000141           0.007361   \n",
      "998             0.025502            0.000141           0.007352   \n",
      "999             0.025483            0.000142           0.007347   \n",
      "\n",
      "     train-merror-std  test-mlogloss-mean  test-mlogloss-std  \\\n",
      "995          0.000086            0.050746           0.000946   \n",
      "996          0.000083            0.050737           0.000947   \n",
      "997          0.000086            0.050730           0.000949   \n",
      "998          0.000089            0.050722           0.000946   \n",
      "999          0.000087            0.050719           0.000949   \n",
      "\n",
      "     test-merror-mean  test-merror-std  \n",
      "995          0.016307         0.000349  \n",
      "996          0.016304         0.000344  \n",
      "997          0.016305         0.000350  \n",
      "998          0.016302         0.000337  \n",
      "999          0.016301         0.000335  \n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb_lib\n",
    "\n",
    "print(\"\\nüîÑ Performing full XGBoost cross-validation (5-fold)...\")\n",
    "\n",
    "dtrain = xgb_lib.DMatrix(X_all, label=y)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": len(le.classes_),\n",
    "    \"eval_metric\": [\"mlogloss\", \"merror\"],\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "cv_results = xgb_lib.cv(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=1000,\n",
    "    nfold=5,\n",
    "    stratified=True,\n",
    "    early_stopping_rounds=30,\n",
    "    metrics=[\"mlogloss\", \"merror\"],\n",
    "    verbose_eval=25,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    as_pandas=True\n",
    ")\n",
    "\n",
    "best_round = len(cv_results)\n",
    "print(f\"\\n‚úÖ Best CV round: {best_round}\")\n",
    "print(cv_results.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a8281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Training set: (519926, 3033)\n",
      "üìÇ Test set: (129982, 3033)\n",
      "\n",
      "üìä Training set class distribution:\n",
      "  benign: 345077 (66.4%)\n",
      "  defacement: 76409 (14.7%)\n",
      "  malware: 20514 (3.9%)\n",
      "  phishing: 77926 (15.0%)\n",
      "  type: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üìå DATA SPLITTING\n",
    "# ===============================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüìÇ Training set: {X_train.shape}\")\n",
    "print(f\"üìÇ Test set: {X_test.shape}\")\n",
    "print(f\"\\nüìä Training set class distribution:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    count = (y_train == i).sum()\n",
    "    print(f\"  {class_name}: {count} ({count/len(y_train)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c940167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training ENHANCED XGBoost classifier...\n",
      "============================================================\n",
      "\n",
      "‚úÖ Training completed in 1777.94 seconds (29.63 minutes)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üìå ENHANCED XGBOOST MODEL\n",
    "# ===============================\n",
    "\n",
    "print(\"\\nüöÄ Training ENHANCED XGBoost classifier...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Enhanced parameters for better learning\n",
    "xgb_final = XGBClassifier(\n",
    "    n_estimators=best_round,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softprob',\n",
    "    num_class=len(le.classes_),\n",
    "    eval_metric=['mlogloss', 'merror'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "xgb_final.fit(X_all, y)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48c738db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä ENHANCED MODEL SUMMARY\n",
      "============================================================\n",
      "\n",
      "‚úÖ Overall Accuracy: 0.9922 (99.22%)\n",
      "‚úÖ F1-Score (Macro): 0.9888\n",
      "‚úÖ F1-Score (Weighted): 0.9921\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.99      1.00      0.99     86270\n",
      "  defacement       1.00      1.00      1.00     19102\n",
      "     malware       1.00      0.97      0.99      5129\n",
      "    phishing       0.98      0.97      0.97     19481\n",
      "\n",
      "    accuracy                           0.99    129982\n",
      "   macro avg       0.99      0.98      0.99    129982\n",
      "weighted avg       0.99      0.99      0.99    129982\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix:\n",
      "[[86055     0     0   215]\n",
      " [    0 19101     0     1]\n",
      " [    4     1  4997   127]\n",
      " [  655    14     0 18812]]\n",
      "\n",
      "üìà Per-Class Metrics:\n",
      "  benign         : Accuracy=0.9975 (99.75%), F1=0.9949\n",
      "  defacement     : Accuracy=0.9999 (99.99%), F1=0.9996\n",
      "  malware        : Accuracy=0.9743 (97.43%), F1=0.9870\n",
      "  phishing       : Accuracy=0.9657 (96.57%), F1=0.9738\n",
      "\n",
      "üîç Top 20 Most Important Features:\n",
      "  has_ip                        : 0.039291\n",
      "  num_subdomains                : 0.004345\n",
      "  domain_length                 : 0.003876\n",
      "  has_https                     : 0.003620\n",
      "  num_slashes                   : 0.002908\n",
      "  has_verify                    : 0.002692\n",
      "  has_secure                    : 0.002196\n",
      "  has_login                     : 0.002042\n",
      "  path_length                   : 0.000971\n",
      "  num_hyphens                   : 0.000717\n",
      "  url_length                    : 0.000644\n",
      "  has_banking                   : 0.000628\n",
      "  num_ampersands                : 0.000610\n",
      "  num_specials                  : 0.000607\n",
      "  num_digits                    : 0.000560\n",
      "  consecutive_digits            : 0.000503\n",
      "  num_ats                       : 0.000490\n",
      "  num_dots                      : 0.000469\n",
      "  num_questions                 : 0.000426\n",
      "  num_equals                    : 0.000369\n",
      "\n",
      "üíæ Saving enhanced model and preprocessors...\n",
      "‚úÖ Enhanced model saved successfully!\n",
      "\n",
      "Model files:\n",
      "  - url_detector_ENHANCED.pkl\n",
      "  - url_tfidf_ENHANCED.pkl\n",
      "  - url_label_ENHANCED.pkl\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üìå COMPREHENSIVE MODEL SUMMARY (No CV)\n",
    "# ===============================\n",
    "\n",
    "# Use the final trained model\n",
    "y_pred = xgb_final.predict(X_test)\n",
    "y_pred_proba = xgb_final.predict_proba(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä ENHANCED MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ------------------------------\n",
    "# Overall performance\n",
    "# ------------------------------\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\n‚úÖ Overall Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "print(f\"‚úÖ F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"‚úÖ F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Classification report\n",
    "# ------------------------------\n",
    "unique_labels = sorted(list(set(y_test) | set(y_pred)))\n",
    "target_names = le.inverse_transform(unique_labels)\n",
    "\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, labels=unique_labels, target_names=target_names))\n",
    "\n",
    "# ------------------------------\n",
    "# Confusion matrix\n",
    "# ------------------------------\n",
    "print(\"\\nüî¢ Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "print(cm)\n",
    "\n",
    "# ------------------------------\n",
    "# Per-class metrics (accurate + stable)\n",
    "# ------------------------------\n",
    "print(\"\\nüìà Per-Class Metrics:\")\n",
    "for i, class_label in enumerate(unique_labels):\n",
    "    class_name = le.inverse_transform([class_label])[0]\n",
    "    class_acc = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
    "    class_f1 = f1_score((y_test == class_label), (y_pred == class_label))\n",
    "    print(f\"  {class_name:15s}: Accuracy={class_acc:.4f} ({class_acc*100:.2f}%), F1={class_f1:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Feature importance\n",
    "# ------------------------------\n",
    "print(\"\\nüîç Top 20 Most Important Features:\")\n",
    "feature_names = list(feature_df.columns)\n",
    "feature_importance = xgb_final.feature_importances_\n",
    "\n",
    "# Slice last N elements for numeric features\n",
    "feature_importance_numeric = feature_importance[-len(feature_names):]\n",
    "\n",
    "top_features = sorted(\n",
    "    zip(feature_names, feature_importance_numeric),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")[:20]\n",
    "\n",
    "for feat, imp in top_features:\n",
    "    print(f\"  {feat:30s}: {imp:.6f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Save final enhanced model\n",
    "# ------------------------------\n",
    "print(\"\\nüíæ Saving enhanced model and preprocessors...\")\n",
    "joblib.dump(xgb_final, \"url_detector_ENHANCED.pkl\")\n",
    "joblib.dump(tfidf, \"url_tfidf_ENHANCED.pkl\")\n",
    "joblib.dump(le, \"url_label_ENHANCED.pkl\")\n",
    "\n",
    "print(\"‚úÖ Enhanced model saved successfully!\")\n",
    "print(\"\\nModel files:\")\n",
    "print(\"  - url_detector_ENHANCED.pkl\")\n",
    "print(\"  - url_tfidf_ENHANCED.pkl\")\n",
    "print(\"  - url_label_ENHANCED.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d735d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
